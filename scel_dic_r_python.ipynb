{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**将搜狗词库(scel)转化为python可读的文本(text)的方法**\n",
    "\n",
    "- 1. 利用R语言（方法简单）\n",
    "\n",
    "① 载入词库\n",
    "```R\n",
    "library(Rwordseg)\n",
    "# getwd()\n",
    "# setwd(\"F:/Jupyter_3/project_py/17-05-30CDA-B-8/05-01_SVM_ANN_BYS\")##设置目录，需要读者手工调整\n",
    "installDict(\"./word_library_scel/程序猿词库.scel\", dictname =\"Coderwords\")\n",
    "\n",
    "# 函数installDict(dictpath, dictname,dicttype = c(\"text\", \"scel\"), load = TRUE)\n",
    "```\n",
    "\n",
    "② 读取文件\n",
    "```python\n",
    "import pandas as pd\n",
    "Coderwords = pd.read_table(\"D:\\\\Users\\\\R\\\\R-3.4.4\\\\library\\\\Rwordseg\\\\dict\\\\Coderwords.dic\",header=None,usecols=[0])\n",
    "```\n",
    "\n",
    "- 2. 利用python转化(注：python版本不一致的话，有可能遇到Bug)\n",
    "\n",
    "参考：最近需要词库来优化分词效果，找到了有大神写好的[能将搜狗词库scel转成txt的python脚本](http://blog.csdn.net/zhangzhenhu/article/details/7014271)\n",
    "\n",
    "实际运行时因为python版本不同转换不能成功，最后终于可行,[scel转txt抽取词库](https://blog.csdn.net/sunlilan/article/details/78761659)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "#!/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import struct\n",
    "import sys\n",
    "import binascii\n",
    "import pdb\n",
    "\n",
    "try:\n",
    "    reload(sys)\n",
    "    sys.setdefaultencoding('utf-8')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# 搜狗的scel词库就是保存的文本的unicode编码，每两个字节一个字符（中文汉字或者英文字母）\n",
    "# 找出其每部分的偏移位置即可\n",
    "# 主要两部分\n",
    "# 1.全局拼音表，貌似是所有的拼音组合，字典序\n",
    "#       格式为(index,len,pinyin)的列表\n",
    "#       index: 两个字节的整数 代表这个拼音的索引\n",
    "#       len: 两个字节的整数 拼音的字节长度\n",
    "#       pinyin: 当前的拼音，每个字符两个字节，总长len\n",
    "#\n",
    "# 2.汉语词组表\n",
    "#       格式为(same,py_table_len,py_table,{word_len,word,ext_len,ext})的一个列表\n",
    "#       same: 两个字节 整数 同音词数量\n",
    "#       py_table_len:  两个字节 整数\n",
    "#       py_table: 整数列表，每个整数两个字节,每个整数代表一个拼音的索引\n",
    "#\n",
    "#       word_len:两个字节 整数 代表中文词组字节数长度\n",
    "#       word: 中文词组,每个中文汉字两个字节，总长度word_len\n",
    "#       ext_len: 两个字节 整数 代表扩展信息的长度，好像都是10\n",
    "#       ext: 扩展信息 前两个字节是一个整数(不知道是不是词频) 后八个字节全是0\n",
    "#\n",
    "#      {word_len,word,ext_len,ext} 一共重复same次 同音词 相同拼音表\n",
    "\n",
    "# 拼音表偏移，\n",
    "startPy = 0x1540;\n",
    "\n",
    "# 汉语词组表偏移\n",
    "startChinese = 0x2628;\n",
    "\n",
    "# 全局拼音表\n",
    "\n",
    "GPy_Table = {}\n",
    "\n",
    "# 解析结果\n",
    "# 元组(词频,拼音,中文词组)的列表\n",
    "GTable = []\n",
    "\n",
    "def byte2str(data):\n",
    "    '''''将原始字节码转为字符串'''\n",
    "    i = 0;\n",
    "    length = len(data)\n",
    "    ret = u''\n",
    "    while i < length:\n",
    "        x = data[i] + data[i + 1]\n",
    "        t = unichr(struct.unpack('H', x)[0])\n",
    "        if t == u'\\r':\n",
    "            ret += u'\\n'\n",
    "        elif t != u' ':\n",
    "            ret += t\n",
    "        i += 2\n",
    "    return ret\n",
    "\n",
    "# 获取拼音表\n",
    "def getPyTable(data):\n",
    "    if data[0:4] != \"\\x9D\\x01\\x00\\x00\":\n",
    "        return None\n",
    "    data = data[4:]\n",
    "    pos = 0\n",
    "    length = len(data)\n",
    "    while pos < length:\n",
    "        index = struct.unpack('H', data[pos] + data[pos + 1])[0]\n",
    "        # print index,\n",
    "        pos += 2\n",
    "        l = struct.unpack('H', data[pos] + data[pos + 1])[0]\n",
    "        # print l,\n",
    "        pos += 2\n",
    "        py = byte2str(data[pos:pos + l])\n",
    "        # print py\n",
    "        GPy_Table[index] = py\n",
    "        pos += l\n",
    "\n",
    "        # 获取一个词组的拼音\n",
    "\n",
    "def getWordPy(data):\n",
    "    pos = 0\n",
    "    length = len(data)\n",
    "    ret = u''\n",
    "    while pos < length:\n",
    "        index = struct.unpack('H', data[pos] + data[pos + 1])[0]\n",
    "        ret += GPy_Table[index]\n",
    "        pos += 2\n",
    "    return ret\n",
    "\n",
    "# 获取一个词组\n",
    "def getWord(data):\n",
    "    pos = 0\n",
    "    length = len(data)\n",
    "    ret = u''\n",
    "    while pos < length:\n",
    "        index = struct.unpack('H', data[pos] + data[pos + 1])[0]\n",
    "        ret += GPy_Table[index]\n",
    "        pos += 2\n",
    "    return ret\n",
    "\n",
    "# 读取中文表\n",
    "def getChinese(data):\n",
    "    # import pdb\n",
    "    # pdb.set_trace()\n",
    "\n",
    "    pos = 0\n",
    "    length = len(data)\n",
    "    while pos < length:\n",
    "        # 同音词数量\n",
    "        same = struct.unpack('H', data[pos] + data[pos + 1])[0]\n",
    "        # print '[same]:',same,\n",
    "\n",
    "        # 拼音索引表长度\n",
    "        pos += 2\n",
    "        py_table_len = struct.unpack('H', data[pos] + data[pos + 1])[0]\n",
    "        # 拼音索引表\n",
    "        pos += 2\n",
    "        py = getWordPy(data[pos: pos + py_table_len])\n",
    "\n",
    "        # 中文词组\n",
    "        pos += py_table_len\n",
    "        for i in xrange(same):\n",
    "            # 中文词组长度\n",
    "            c_len = struct.unpack('H', data[pos] + data[pos + 1])[0]\n",
    "            # 中文词组\n",
    "            pos += 2\n",
    "            word = byte2str(data[pos: pos + c_len])\n",
    "            # 扩展数据长度\n",
    "            pos += c_len\n",
    "            ext_len = struct.unpack('H', data[pos] + data[pos + 1])[0]\n",
    "            # 词频\n",
    "            pos += 2\n",
    "            count = struct.unpack('H', data[pos] + data[pos + 1])[0]\n",
    "\n",
    "            # 保存\n",
    "            GTable.append((count, py, word))\n",
    "\n",
    "            # 到下个词的偏移位置\n",
    "            pos += ext_len\n",
    "\n",
    "def deal(file_name):\n",
    "    print ('-' * 60)\n",
    "    f = open(file_name, 'rb')\n",
    "    data = f.read()\n",
    "    f.close()\n",
    "\n",
    "#     if data[0:12] != \"\\x40\\x15\\x00\\x00\\x44\\x43\\x53\\x01\\x01\\x00\\x00\\x00\":\n",
    "    if data[0:12] != bytes(map(ord,\"\\x40\\x15\\x00\\x00\\x44\\x43\\x53\\x01\\x01\\x00\\x00\\x00\")):        \n",
    "        print (\"确认你选择的是搜狗(.scel)词库?\")\n",
    "        sys.exit(0)\n",
    "        # pdb.set_trace()\n",
    "\n",
    "    print (\"词库名：\", byte2str(data[0x130:0x338]))  # .encode('GB18030')\n",
    "    print (\"词库类型：\", byte2str(data[0x338:0x540]))  # .encode('GB18030')\n",
    "    print (\"描述信息：\", byte2str(data[0x540:0xd40]))  # .encode('GB18030')\n",
    "    print (\"词库示例：\", byte2str(data[0xd40:startPy]))  # .encode('GB18030')\n",
    "\n",
    "    getPyTable(data[startPy:startChinese])\n",
    "    getChinese(data[startChinese:])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # 将要转换的词库添加在这里就可以了\n",
    "    o = ['./word_library_scel/编程语言.scel']\n",
    "\n",
    "    for f in o:\n",
    "        deal(f)\n",
    "\n",
    "        # 保存结果\n",
    "    f = open('code.txt', 'w')\n",
    "    for word in GTable:\n",
    "        # GTable保存着结果，是一个列表，每个元素是一个元组(词频,拼音,中文词组)，有需要的话可以保存成自己需要个格式\n",
    "        # 我没排序，所以结果是按照上面输入文件的顺序\n",
    "        #f.write(unicode(word).encode('GB18030'))  # 最终保存文件的编码，可以自给改\n",
    "        f.write(word[2])\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
